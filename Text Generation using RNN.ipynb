{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2c3fc4",
   "metadata": {},
   "source": [
    "# 1) 데이터에 대한 이해와 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b2c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #토크나이저 => 단어집합을 생성시켜준다.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # 벡터를 패딩시켜준다.\n",
    "from tensorflow.keras.utils import to_categorical #원-핫 인코딩|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c66d95",
   "metadata": {},
   "source": [
    "# 코퍼스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9400d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b94af1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n",
      "단어집합의 크기 12\n"
     ]
    }
   ],
   "source": [
    "#단어집합을 생성하고 크기를 확인\n",
    "# 1. 정수 인코딩\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text]) #단어 집합을 생성\n",
    "print(tokenizer.word_index)\n",
    "vocab_size = len(tokenizer.word_index)+1 #패딩을 위한 0을 고려\n",
    "print('단어집합의 크기 %d' % vocab_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc0901",
   "metadata": {},
   "source": [
    "# 훈련데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d5d358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 11\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in text.split('\\n'): # 줄바꿈 문자 기준으로 코퍼스 분리\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0] #문장을 정수 토큰화\n",
    "    for i in range(1, len(encoded)): # 1~문장의 길이\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ac27f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences\n",
    "#위 데이터는 레이블로 사용될 단어를 분리하지 않은 훈련데이터이다.\n",
    "#전체 훈련데이터에 대해서 맨 우측에 있는 단어만 대해서만 레이블로 븐리해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ed72a",
   "metadata": {},
   "source": [
    "# 훈련데이터 길이 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d539ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 6\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f5b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 샘플의 길이를 6으로 맞춰준다.\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd59585c",
   "metadata": {},
   "source": [
    "pad_sequences()는 모든 샘플에 대해서 0을 사용하여 길이를 맞춰줍니다. maxlen의 값으로 6을 주면 모든 샘플의 길이를 6으로 맞춰주며, padding의 인자로 'pre'를 주면 길이가 6보다 짧은 샘플의 앞에 0으로 채웁니다. 전체 훈련 데이터를 출력해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a1b97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46968b",
   "metadata": {},
   "source": [
    "# 각 샘플의 마지막 단어를 레이블로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c7527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#레이블븐리는 Numpy를 사용해서 가능\n",
    "import numpy as np\n",
    "np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e84b382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X : 리스트의 마지막 값을 제외하고 저장 -> 입력데이터\n",
    "# y : 리스트의 마지막 값만을 저장 -> 레이블 \n",
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1] # 2차원 배열\n",
    "y = sequences[:,-1] # 1차원 벡터(레이블)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "370892e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  2,  3,  1],\n",
       "       [ 0,  2,  3,  1,  4],\n",
       "       [ 0,  0,  0,  0,  6],\n",
       "       [ 0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  0,  8],\n",
       "       [ 0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  8,  1,  9],\n",
       "       [ 0,  8,  1,  9, 10],\n",
       "       [ 8,  1,  9, 10,  1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # 입력 벡터의 크기 (maxlen-1 : 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f704ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4,  5,  1,  7,  1,  9, 10,  1, 11])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ef3e37",
   "metadata": {},
   "source": [
    "# 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9639f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블이 분리되었습니다. RNN 모델에 훈련 데이터를 훈련 시키기 전에 레이블에 대해서 원-핫 인코딩을 수행합니다.\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87eea290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9df6c17",
   "metadata": {},
   "source": [
    "갑분 정리\n",
    "RNNLM은 입력 길이에 상관없이 시점 개념을 적용하여 다음 단어를 예측 가능하다.\n",
    "RNNLM은 기본적을 예측과정에서 이전 출력을 현재시점의 입력으로 합니다.\n",
    "교사 강요 방식 : 테스트 과정에서 t 시점의 출력이 t+1 시점의 입력으로 사용되는 RNN 모델을 훈련시킬 때 사용하는 훈련 기법입니다. 단 훈련시에는 이전 시점의 출력이 아닌 이전 시점의 레이블(알고 있는 정답)을 입력을 사용한다.\n",
    "cf) 데이터 처리 와 모델링\n",
    "1. 데이터\n",
    "    1. 훈련 코퍼스 정수 인코딩 -> Tokenizer\n",
    "    2. 인코딩 벡터를 동일 길이로 패딩 -> pad_sequences\n",
    "    3. 인코딩 벡터를 입력 데이터 X와 출력 레이블y 로 분리\n",
    "    4. 출력 레이블 y를 원-핫인코딩\n",
    "2. 모델링\n",
    "    input layer : 입력 벡터(V)(=단어 집합의 크기)\n",
    "    Embedding layer : 임베딩 층 (V, M), 임베딩 벡터 : M\n",
    "    Hidden layer : 은닉 상태 ht \n",
    "    Output layer : 출력층(소프트 맥스) / 입력 벡터의크기(V) / cross-entropy 지수로 나온다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33060be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f086534",
   "metadata": {},
   "source": [
    "# 모델설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "733dea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6339f37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 2.5082 - accuracy: 0.0000e+00 - 772ms/epoch - 772ms/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4947 - accuracy: 0.0000e+00 - 2ms/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4813 - accuracy: 0.0909 - 2ms/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4681 - accuracy: 0.0909 - 2ms/epoch - 2ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4548 - accuracy: 0.1818 - 2ms/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4413 - accuracy: 0.1818 - 2ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.4276 - accuracy: 0.2727 - 2ms/epoch - 2ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.4135 - accuracy: 0.2727 - 2ms/epoch - 2ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3989 - accuracy: 0.2727 - 2ms/epoch - 2ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3838 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.3680 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.3514 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.3340 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.3157 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.2965 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.2763 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.2551 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.2329 - accuracy: 0.3636 - 997us/epoch - 997us/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.2098 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.1857 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.1609 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.1355 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.1097 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.0837 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 2.0578 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 2.0325 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 2.0081 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 1.9848 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 1.9631 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 1.9432 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 1.9251 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.9087 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.8938 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.8799 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.8665 - accuracy: 0.3636 - 997us/epoch - 997us/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.8532 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.8393 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.8247 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.8093 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.7930 - accuracy: 0.3636 - 997us/epoch - 997us/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.7761 - accuracy: 0.3636 - 997us/epoch - 997us/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.7589 - accuracy: 0.3636 - 997us/epoch - 997us/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.7417 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.7246 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.7079 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.6917 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.6757 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.6600 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.6443 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.6283 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.6120 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.5950 - accuracy: 0.4545 - 2ms/epoch - 2ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.5774 - accuracy: 0.4545 - 2ms/epoch - 2ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.5591 - accuracy: 0.4545 - 3ms/epoch - 3ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.5401 - accuracy: 0.4545 - 2ms/epoch - 2ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.5205 - accuracy: 0.4545 - 2ms/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.5003 - accuracy: 0.4545 - 2ms/epoch - 2ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.4796 - accuracy: 0.4545 - 2ms/epoch - 2ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.4585 - accuracy: 0.4545 - 3ms/epoch - 3ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.4370 - accuracy: 0.5455 - 2ms/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.4150 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.3927 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.3700 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.3470 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.3236 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.2999 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.2760 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.2519 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.2278 - accuracy: 0.6364 - 997us/epoch - 997us/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.2038 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.1799 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.1563 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.1330 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.1100 - accuracy: 0.7273 - 998us/epoch - 998us/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.0873 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.0651 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.0432 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.0218 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.0009 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 0.9803 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 0.9603 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 0.9407 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 0.9217 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 0.9030 - accuracy: 0.7273 - 997us/epoch - 997us/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.8849 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.8672 - accuracy: 0.7273 - 997us/epoch - 997us/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.8499 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.8331 - accuracy: 0.7273 - 997us/epoch - 997us/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.8167 - accuracy: 0.7273 - 997us/epoch - 997us/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.8007 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.7851 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.7699 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.7551 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.7406 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.7264 - accuracy: 0.7273 - 997us/epoch - 997us/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.7126 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.6991 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.6858 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.6729 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.6602 - accuracy: 0.9091 - 997us/epoch - 997us/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.6477 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.6355 - accuracy: 0.9091 - 997us/epoch - 997us/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.6236 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.6119 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.6004 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.5891 - accuracy: 0.9091 - 996us/epoch - 996us/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.5781 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.5672 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.5566 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.5461 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.5359 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.5258 - accuracy: 0.9091 - 998us/epoch - 998us/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.5159 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.5063 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.4967 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.4874 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.4782 - accuracy: 0.9091 - 983us/epoch - 983us/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.4692 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.4604 - accuracy: 0.9091 - 997us/epoch - 997us/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.4517 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.4432 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.4348 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.4266 - accuracy: 0.9091 - 968us/epoch - 968us/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.4185 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.4106 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.4028 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.3951 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.3876 - accuracy: 0.9091 - 997us/epoch - 997us/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.3802 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.3730 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.3659 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.3589 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.3520 - accuracy: 0.9091 - 998us/epoch - 998us/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.3452 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.3386 - accuracy: 0.9091 - 1ms/epoch - 1ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.3321 - accuracy: 0.9091 - 998us/epoch - 998us/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.3257 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.3195 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.3133 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.3073 - accuracy: 0.9091 - 996us/epoch - 996us/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.3013 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.2955 - accuracy: 0.9091 - 996us/epoch - 996us/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.2898 - accuracy: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.2842 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.2787 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.2733 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.2680 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.2628 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.2577 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.2527 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.2479 - accuracy: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.2431 - accuracy: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.2384 - accuracy: 1.0000 - 996us/epoch - 996us/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.2338 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.2293 - accuracy: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.2248 - accuracy: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.2205 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.2163 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.2121 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.2081 - accuracy: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2041 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.2002 - accuracy: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.1964 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.1927 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.1890 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.1855 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.1820 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.1786 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.1752 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.1720 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.1688 - accuracy: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.1657 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.1626 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.1596 - accuracy: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.1567 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.1539 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.1511 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.1483 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.1457 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.1431 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.1405 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1380 - accuracy: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.1356 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.1332 - accuracy: 1.0000 - 997us/epoch - 997us/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1309 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1286 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1264 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1243 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1221 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1201 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1180 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1160 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1141 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1122 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.1103 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.1085 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.1068 - accuracy: 1.0000 - 998us/epoch - 998us/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.1050 - accuracy: 1.0000 - 996us/epoch - 996us/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.1033 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.1017 - accuracy: 1.0000 - 997us/epoch - 997us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d70e1e1a30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RNN모델에 데이터를 훈련시킵니다.\n",
    "#다대일 구조의 RNN을 사용하빈다.\n",
    "embedding_dim = 10 # 임베딩 벡터의 차원\n",
    "hidden_units = 32 #은닉상태의 크기\n",
    "#입력벡터의 크기\n",
    "\n",
    "#Embedding('입력벡터의 크기(차원)', '츌력(임베딩 벡터)의 크기', input_length) \n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim)) #임베딩층 구성 \n",
    "model.add(SimpleRNN(hidden_units)) #은닉상태 크기\n",
    "model.add(Dense(vocab_size, activation='softmax')) #출력층 (FC/ 출력 벡터로 단어크기만큼)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X, y, epochs=200, verbose=2)\n",
    "\n",
    "#마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 모델"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "867c78c6",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7308c64",
   "metadata": {},
   "source": [
    "# 문장을 생성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63020e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word #시작 단어\n",
    "    sentence = ''\n",
    "    # n번 반복 4번 반복 현재단어(t) +예측단어(t+1)+예측단어(t+2)+예측단어(t+3)+예측단어(t+4)\n",
    "    for _ in range(n):\n",
    "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0] #현재 단어 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') #최대길이 5로 padding / 왜 5인가. 훈련 샘플 최대 길이 6에서 맨마지막 레이블 을 빼버렸으니 5이다.\n",
    "        print(encoded)\n",
    "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0) # 엔트로파 벡터(에측 벡터)\n",
    "        result= np.argmax(result, axis=1) #예측 벡터의 가장큰 값의 인덱스를 저장\n",
    "        \n",
    "    \n",
    "        for word, index in tokenizer.word_index.items(): #단어사전에서\n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
    "            if index == result: #예측한 단어와 동일한 단어가 있다면\n",
    "                break\n",
    "\n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        current_word = current_word + ' '  + word\n",
    "        print(current_word)\n",
    "        # 입력 : 경마장에\n",
    "        # 예측1 : current_word : 경마장에(정수인코딩 -> 패딩 ) -> 예측  -> '있는'\n",
    "        # 예측2: current_word : '경마장에 있는' -> 에측 -> '말이'\n",
    "        # 예측3: current_word : 예측 '뛰고' \n",
    "        # 예측4: current_word : 예측 '있다.' \n",
    "\n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3cff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 2]]\n",
      "경마장에 있는\n",
      "[[0 0 0 2 3]]\n",
      "경마장에 있는 말이\n",
      "[[0 0 2 3 1]]\n",
      "경마장에 있는 말이 뛰고\n",
      "[[0 2 3 1 4]]\n",
      "경마장에 있는 말이 뛰고 있다\n",
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '경마장에', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80edca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]]\n",
      "바나나 말이\n",
      "[[0 0 0 0 1]]\n",
      "바나나 말이 말이\n",
      "바나나 말이 말이\n"
     ]
    }
   ],
   "source": [
    "#없는 단어 예측\n",
    "print(sentence_generation(model, tokenizer, '바나나', 2)) # 두번 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43378fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[[0 0 0 0 1]]이 무엇인가 과연 모델이 학습을 했는가 학습을 하지 않아서 이상한 예측값을 내놓는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d7c8fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'말이': 1,\n",
       " '경마장에': 2,\n",
       " '있는': 3,\n",
       " '뛰고': 4,\n",
       " '있다': 5,\n",
       " '그의': 6,\n",
       " '법이다': 7,\n",
       " '가는': 8,\n",
       " '고와야': 9,\n",
       " '오는': 10,\n",
       " '곱다': 11}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c22be2e",
   "metadata": {},
   "source": [
    "샘플이 어떠한가\n",
    "초기단어 + 여려개의 단어\n",
    "에서\n",
    "X = [:-1] 과 y = [-1]로 분리시켰다.\n",
    "y는 초기단어 제외 원-핫벡터이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b5c0988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 8 1]]\n",
      "가는 말이 고와야\n",
      "[[0 0 8 1 9]]\n",
      "가는 말이 고와야 오는\n",
      "[[ 0  8  1  9 10]]\n",
      "가는 말이 고와야 오는 말이\n",
      "[[ 8  1  9 10  1]]\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '가는 말이', 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3f1f6",
   "metadata": {},
   "source": [
    "# 2. LSTM을 이용하여 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e1b205c",
   "metadata": {},
   "source": [
    "이번에는 LSTM을 통해 보다 많은 데이터로 텍스트를 생성해보겠습니다. 본질적으로 앞에서 한 것과 동일한 실습입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cce20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6328a47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'C:\\\\Users\\\\DanielJeong\\\\PycharmProjects\\\\OceanData'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0f81ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount  \\\n",
       "0  5adf6684068401528a2aa69b               781   \n",
       "1  5adf653f068401528a2aa697               656   \n",
       "2  5adf4626068401528a2aa628              2427   \n",
       "3  5adf40d2068401528a2aa619               626   \n",
       "4  5adf3d64068401528a2aa60f               815   \n",
       "\n",
       "                                      byline documentType  \\\n",
       "0                             By JOHN BRANCH      article   \n",
       "1                           By LISA FRIEDMAN      article   \n",
       "2                              By PETE WELLS      article   \n",
       "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
       "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                            keywords  multimedia     newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
       "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
       "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "3          0  2018-04-24 14:35:57        Europe   \n",
       "4          0  2018-04-24 14:21:21        Canada   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
       "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
       "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
       "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ArticlesApril2018.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eb4b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열의 개수 15\n"
     ]
    }
   ],
   "source": [
    "print('열의 개수', len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f3057c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
      "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
      "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bba253d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.headline.isnull().values.any()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b68ab816",
   "metadata": {},
   "source": [
    "Null 값은 별도로 없는 것으로 보입니다. headline 열에서 모든 신문 기사의 제목을 뽑아서 하나의 리스트로 저장해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3ac7806",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = []\n",
    "headline.extend(list(df.headline.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b21b6eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50759767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 1324\n"
     ]
    }
   ],
   "source": [
    "# 노이즈 제거\n",
    "print('총 샘플의 개수 : {}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce7afa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노이즈값 제거 후 샘플의 개수 : 1214\n"
     ]
    }
   ],
   "source": [
    "headline = [word for word in headline if word != \"Unknown\"]\n",
    "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "908e9a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3530d13",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "## 구두점 제거, 소문자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d300d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repreprocessing(raw_sentence):\n",
    "    #utf-8 -> 아스키 코드로 변환\n",
    "    preproceseed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    # 구두점 제거와 동시에 소문자화\n",
    "    return ''.join(word for word in preproceseed_sentence if word not in punctuation).lower()\n",
    "\n",
    "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
    "preprocessed_headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b8e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
