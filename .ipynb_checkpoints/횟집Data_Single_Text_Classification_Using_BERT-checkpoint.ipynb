{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c59b3c",
   "metadata": {},
   "source": [
    "# 1. 데이터 로드, 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59377efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3494bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('result.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f300990d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2932"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3e11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련데이터와 테스트데이터 분리\n",
    "data = dataset['Review']\n",
    "target = dataset['Label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,target,test_size=0.2,shuffle=True,stratify=target,random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420ee1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 :  2345\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 수 : ', len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5226d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787067e",
   "metadata": {},
   "source": [
    "# 2. BERT - FineTuning(Sentence analasis)\n",
    "## 2-1. 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c1208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e079052",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = x_train.tolist()\n",
    "X_test_list = x_test.tolist()\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d47117",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(X_train_list, truncation=True, padding=True)\n",
    "X_test = tokenizer(X_test_list, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344b2862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '상', '##다리', '휘', '##어질', '##정', '##도로', '푸짐', '##하', '##게', '잘', '##나', '##오', '##고', '친절', '##하고', '맛있', '##어요', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a19741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1242, 6982, 1952, 7424, 2287, 6896, 12252, 2205, 2318, 1521, 2075, 2168, 2088, 7798, 19521, 4550, 10283, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5eb4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0333928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df3c6b",
   "metadata": {},
   "source": [
    "## 2-2. 데이터셋 생성 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db3fef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_train),\n",
    "    y_train\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_test),\n",
    "    y_test\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec729f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87843d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e93f2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=2, from_pt=True)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12d5a59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TFPreTrainedModel.compute_loss of <transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification object at 0x00000153A5A63F40>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7495f085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DanielJeong\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 59s 588ms/step - loss: 0.2355 - accuracy: 0.9006 - val_loss: 0.1275 - val_accuracy: 0.9404\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 41s 551ms/step - loss: 0.1007 - accuracy: 0.9625 - val_loss: 0.1800 - val_accuracy: 0.9353\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 41s 552ms/step - loss: 0.0313 - accuracy: 0.9910 - val_loss: 0.1926 - val_accuracy: 0.9438\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 41s 554ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.2188 - val_accuracy: 0.9404\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 41s 551ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.1631 - val_accuracy: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c535b2820>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_earlystop = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    min_delta=0.001,\n",
    "    patience=2)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset.shuffle(10000).batch(32), epochs=5, batch_size=64,\n",
    "    validation_data = val_dataset.shuffle(10000).batch(64),\n",
    "    callbacks = [callback_earlystop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8908dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.1631 - accuracy: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16314516961574554, 0.9522998332977295]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_dataset.batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c120d68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nsmc_model/bert-base\\\\tokenizer_config.json',\n",
       " 'nsmc_model/bert-base\\\\special_tokens_map.json',\n",
       " 'nsmc_model/bert-base\\\\vocab.txt',\n",
       " 'nsmc_model/bert-base\\\\added_tokens.json',\n",
       " 'nsmc_model/bert-base\\\\tokenizer.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('BERT_model/bert-base')\n",
    "tokenizer.save_pretrained('BERT_model/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "024ecb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at BERT_model/bert-base were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at BERT_model/bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "C:\\Users\\DanielJeong\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pipelines\\text_classification.py:89: UserWarning: `return_all_scores` is now deprecated, use `top_k=1` if you want similar functionnality\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# 로드하기\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained('BERT_model/bert-base')\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained('BERT_model/bert-base')\n",
    "\n",
    "text_classifier = TextClassificationPipeline(\n",
    "    tokenizer=loaded_tokenizer, \n",
    "    model=loaded_model, \n",
    "    framework='tf',\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca553a7",
   "metadata": {},
   "source": [
    "## 2-3. 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8151a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sentiment(text):\n",
    "    result = text_classifier(text)[0]\n",
    "    print('부정일 확률 : ', round(result[0]['score'],3))\n",
    "    print('긍정일 확률 : ', round(result[1]['score'],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74a87ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9952921867370605},\n",
       " {'label': 'LABEL_1', 'score': 0.00470778439193964}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classifier('위생상태 불량')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84c54d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.993\n",
      "긍정일 확률 :  0.007\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('위생불량')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f2c222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.996\n",
      "긍정일 확률 :  0.004\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('장소가 협소하네요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfd9db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.984\n",
      "긍정일 확률 :  0.016\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('비린맛이 심하네요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "080715d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.998\n",
      "긍정일 확률 :  0.002\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('맛은 좋지만 가성비가 떨어지네요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e97ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.001\n",
      "긍정일 확률 :  0.999\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('알바가 친절하고 맛도 좋아요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6da2480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.001\n",
      "긍정일 확률 :  0.999\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('가성비 좋고, 맛도 무진장 좋아요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b57510b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.979\n",
      "긍정일 확률 :  0.021\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('가성비 좋고, 맛도 무진장 좋아요. 그런데 주차자리가 협소하네요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ab52e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.002\n",
      "긍정일 확률 :  0.998\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('굿')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea815f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.002\n",
      "긍정일 확률 :  0.998\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('개 좋다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55fa60a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.916\n",
      "긍정일 확률 :  0.084\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('개 같다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "535c3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정일 확률 :  0.985\n",
      "긍정일 확률 :  0.015\n"
     ]
    }
   ],
   "source": [
    "show_sentiment('장사가 잘되니 초심을 잃었네요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3101e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
